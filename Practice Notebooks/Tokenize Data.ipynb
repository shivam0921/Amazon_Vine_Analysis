{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tokenize Data.ipynb","provenance":[],"authorship_tag":"ABX9TyMQZGLNNcsBt6pMes+BhF9S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-TIihU1nu3o","executionInfo":{"status":"ok","timestamp":1616706897271,"user_tz":240,"elapsed":38021,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}},"outputId":"2ba2f04e-1b43-4432-9007-1e0baa3e7d47"},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.2'\n","spark_version = 'spark-3.0.2'\n","os.environ['SPARK_VERSION']=spark_version\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r                                                                               \rHit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [3 InRelease 64.9 kB/88.7 kB 73%] [Waiting for headers] [Waiting for headers\r0% [2 InRelease gpgv 242 kB] [3 InRelease 70.7 kB/88.7 kB 80%] [Waiting for hea\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Waiti\r                                                                               \rHit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","\r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to ppa.launchpad\r                                                                               \rGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [2 InRelease gpgv 242 kB] [8 InRelease 20.5 kB/74.6 kB 27%] [Waiting for hea\r                                                                               \r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\r                                                                        \rGet:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,402 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,045 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [348 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,748 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [894 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,475 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,170 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [378 kB]\n","Get:22 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [49.4 kB]\n","Fetched 11.8 MB in 3s (4,056 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WJiHUIgon7tU","executionInfo":{"status":"ok","timestamp":1616706958955,"user_tz":240,"elapsed":8957,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vMQAXAroONa","executionInfo":{"status":"ok","timestamp":1616706959208,"user_tz":240,"elapsed":5267,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["from pyspark.ml.feature import Tokenizer"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SeOEfE4qSQg","executionInfo":{"status":"ok","timestamp":1616706961680,"user_tz":240,"elapsed":5428,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["#creating a Sample Data Frame\n","dataframe = spark.createDataFrame([\n","     (0, \"Using Spark Is Great\"),\n","     (1, \"We are learning Spark\"),\n","     (2, \"Spark is better than Hadoop\")                              \n","],[\"id\" , \"sentence\"])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToW7t0DuqXa5","executionInfo":{"status":"ok","timestamp":1616706964894,"user_tz":240,"elapsed":6907,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}},"outputId":"833d0e5f-d1de-4751-8e7f-4e9fe50259e6"},"source":["dataframe.show()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|Using Spark Is Great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CVPP_XaNq8FT","executionInfo":{"status":"ok","timestamp":1616706964895,"user_tz":240,"elapsed":5848,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}},"outputId":"290baba1-8a8b-4176-fdd0-d6e4798382a9"},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_2085547920a2"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQyG6OzksP62","executionInfo":{"status":"ok","timestamp":1616706965814,"user_tz":240,"elapsed":5593,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}},"outputId":"961d4110-fe3c-45fe-a995-1fe0ea4278e7"},"source":["# Transform and show DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate=False)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["+---+---------------------------+---------------------------------+\n","|id |sentence                   |words                            |\n","+---+---------------------------+---------------------------------+\n","|0  |Using Spark Is Great       |[using, spark, is, great]        |\n","|1  |We are learning Spark      |[we, are, learning, spark]       |\n","|2  |Spark is better than Hadoop|[spark, is, better, than, hadoop]|\n","+---+---------------------------+---------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KJPhKLQRsdnv","executionInfo":{"status":"ok","timestamp":1616706965814,"user_tz":240,"elapsed":3816,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"59wUj5AwsgoX","executionInfo":{"status":"ok","timestamp":1616706965815,"user_tz":240,"elapsed":2865,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnL8MWDrsj9Y","executionInfo":{"status":"ok","timestamp":1616706965816,"user_tz":240,"elapsed":1816,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"izjGQxw3slvy","executionInfo":{"status":"ok","timestamp":1616706965817,"user_tz":240,"elapsed":845,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["# Create our Tokenizer\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqSedW2tsybw","executionInfo":{"status":"ok","timestamp":1616707003554,"user_tz":240,"elapsed":673,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}}},"source":["# Transform DataFrame\n","tokenized_df = tokenizer.transform(dataframe)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_L7bP00PyHP","executionInfo":{"status":"ok","timestamp":1616707388780,"user_tz":240,"elapsed":1360,"user":{"displayName":"Shivam Mittal","photoUrl":"","userId":"02681500268791522921"}},"outputId":"0503c325-db7a-4bd5-cc9f-b0e49a5053cf"},"source":["#Select the needed Columns and don't Truncate results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["+---+---------------------------+---------------------------------+------+\n","|id |sentence                   |words                            |tokens|\n","+---+---------------------------+---------------------------------+------+\n","|0  |Using Spark Is Great       |[using, spark, is, great]        |4     |\n","|1  |We are learning Spark      |[we, are, learning, spark]       |4     |\n","|2  |Spark is better than Hadoop|[spark, is, better, than, hadoop]|5     |\n","+---+---------------------------+---------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5_94rA3PRP_u"},"source":[""],"execution_count":null,"outputs":[]}]}